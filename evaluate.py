#!/usr/bin/env python3
"""
MobileNetV3-Large (minimalistic) â€“ í…ŒìŠ¤íŠ¸ & ë©”íŠ¸ë¦­ ê³„ì‚°
1. í•™ìŠµì— ì‚¬ìš©í•œ config.yamlì„ ê·¸ëŒ€ë¡œ ë¶ˆëŸ¬ì™€ ë™ì¼í•œ ì „ì²˜ë¦¬Â·ë¶„í•  ì¬í˜„
2. best_model_saved/ ë˜ëŠ” best.kerasë¥¼ ì½ì–´ ëª¨ë¸ ë³µì›
3. í…ŒìŠ¤íŠ¸ì…‹ ì „ì²´ì— ëŒ€í•´
   â–ªï¸ ì •í™•ë„(Accuracy)
   â–ªï¸ í´ë˜ìŠ¤ë³„ Precision / Recall / F1
   â–ªï¸ í´ë˜ìŠ¤ë³„ ì •í™•ë„
   â–ªï¸ Confusion Matrix
4. ê²°ê³¼ë¥¼ ì½˜ì†” ì¶œë ¥ (ì¶”í›„ CSVÂ·ê·¸ë˜í”„ ì €ì¥ë„ ì‰½ê²Œ í™•ì¥ ê°€ëŠ¥)
"""

import os, yaml, collections
from pathlib import Path
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.metrics import (
    classification_report, confusion_matrix, precision_recall_fscore_support
)
from tqdm import tqdm

# â”€â”€ 0. ì„¤ì • ë¡œë“œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# â”€â”€ 0. ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
CFG = yaml.safe_load(open("config.yaml"))
IMG = (CFG["img_height"], CFG["img_width"])
IMG_SIZE   = (CFG["img_height"], CFG["img_width"])
BATCH = CFG["batch_size"]; SEED = CFG["seed"]
VAL_RATE = CFG["valtest_split"]; DATA = Path(CFG["data_dir"])
E_HEAD, E_FINE = CFG["epochs_head"], CFG["epochs_fine"]
LR_HEAD, LR_FINE = CFG["initial_lr"], CFG["fine_tune_lr"]
UNFREEZE_AT = CFG["unfreeze_from"]; ALPHA = CFG["depth_multiplier"]

tf.keras.utils.set_random_seed(SEED)

tf.keras.utils.set_random_seed(SEED)

# â”€â”€ 1. í…ŒìŠ¤íŠ¸ì…‹ ì¬êµ¬ì„± (í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ë¶„í•  ë°©ì‹) â”€â”€â”€â”€â”€â”€â”€
train_ds = keras.utils.image_dataset_from_directory(
    DATA, label_mode="int", image_size=IMG, batch_size=BATCH,
    validation_split=VAL_RATE, subset="training", seed=SEED)
valtest_ds = keras.utils.image_dataset_from_directory(
    DATA, label_mode="int", image_size=IMG, batch_size=BATCH,
    validation_split=VAL_RATE, subset="validation", seed=SEED)
val_cnt = tf.data.experimental.cardinality(valtest_ds).numpy() // 2
val_ds  = valtest_ds.take(val_cnt); test_ds = valtest_ds.skip(val_cnt)

CLASSES = train_ds.class_names; N = len(CLASSES)
N       = len(CLASSES)
print("í´ë˜ìŠ¤:", CLASSES)

prep = keras.applications.mobilenet_v3.preprocess_input
test_ds = test_ds.map(lambda x,y: (prep(x), y)).prefetch(tf.data.AUTOTUNE)

# â”€â”€ 2. ëª¨ë¸ ë³µì› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_DIR = Path("best_model_saved")     # SavedModel ë””ë ‰í„°ë¦¬
WEIGHT_KR = Path("best.keras")           # ê°€ì¤‘ì¹˜ íŒŒì¼

if MODEL_DIR.exists():
    model = keras.models.load_model(MODEL_DIR)
elif WEIGHT_KR.exists():
    # í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼ êµ¬ì¡°ë¡œ ëª¨ë¸ ì¬ì •ì˜ í›„ ê°€ì¤‘ì¹˜ ë¡œë“œ
    base = keras.applications.MobileNetV3Large(
        input_shape=IMG_SIZE+(3,), include_top=False, minimalistic=True,
        alpha=CFG["depth_multiplier"], weights=None
    )
    inputs = keras.Input(shape=IMG_SIZE+(3,))
    x = base(inputs, training=False)
    x = layers.GlobalAveragePooling2D()(x)
    x = layers.Dropout(0.3)(x)
    outputs = layers.Dense(N, activation="softmax")(x)
    model = keras.Model(inputs, outputs)
    model.load_weights(WEIGHT_KR)
else:
    raise FileNotFoundError("ë³µì›í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")

print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

# â”€â”€ 3. ì˜ˆì¸¡ ìˆ˜í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
y_true, y_pred = [], []
for batch_x, batch_y in tqdm(test_ds):
    preds = model.predict(batch_x, verbose=0)
    y_true.extend(batch_y.numpy())
    y_pred.extend(np.argmax(preds, axis=1))

y_true = np.array(y_true)
y_pred = np.array(y_pred)

# â”€â”€ 4-A. ì „ì²´ ì •í™•ë„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
acc = (y_true == y_pred).mean()
print(f"\nğŸ“Š  Test Accuracy: {acc*100:5.2f}%")

# â”€â”€ 4-B. í´ë˜ìŠ¤ë³„ Precision / Recall / F1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
report = classification_report(
    y_true, y_pred, target_names=CLASSES, digits=4
)
print("\n=== Classification Report ===")
print(report)

# â”€â”€ 4-C. í´ë˜ìŠ¤ë³„ ì •í™•ë„ë§Œ ë³„ë„ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cls_correct = collections.Counter()
cls_total   = collections.Counter()
for t, p in zip(y_true, y_pred):
    cls_total[int(t)]   += 1
    if t == p:
        cls_correct[int(t)] += 1
print("=== Per-class Accuracy ===")
for i, name in enumerate(CLASSES):
    acc_i = cls_correct[i] / cls_total[i]
    print(f"{name:<25}: {acc_i*100:5.2f}%  ({cls_correct[i]}/{cls_total[i]})")

# â”€â”€ 4-D. Confusion Matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
cm = confusion_matrix(y_true, y_pred, labels=range(N))
print("\n=== Confusion Matrix (raw counts) ===")
print(cm)

# í•„ìš” ì‹œ: np.savetxt("confusion_matrix.csv", cm, fmt="%d", delimiter=",")
